{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "KpyNc5MltqjA"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from platform import python_version\n",
        "from sklearn.decomposition import PCA\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision.utils as vutils\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision import datasets\n",
        "import torchvision.transforms as T\n",
        "import torch.nn.functional as F\n",
        "import torch.utils.data as data_utils\n",
        "import matplotlib.animation as animation\n",
        "from IPython.display import HTML"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting wget\n",
            "  Downloading wget-3.2.zip (10 kB)\n",
            "  Preparing metadata (setup.py): started\n",
            "  Preparing metadata (setup.py): finished with status 'done'\n",
            "Installing collected packages: wget\n",
            "  Running setup.py install for wget: started\n",
            "  Running setup.py install for wget: finished with status 'done'\n",
            "Successfully installed wget-3.2\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  DEPRECATION: wget is being installed using the legacy 'setup.py install' method, because it does not have a 'pyproject.toml' and the 'wheel' package is not installed. pip 23.1 will enforce this behaviour change. A possible replacement is to enable the '--use-pep517' option. Discussion can be found at https://github.com/pypa/pip/issues/8559\n",
            "\n",
            "[notice] A new release of pip is available: 23.0.1 -> 23.1.1\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "!pip install wget"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Data Preperation\n",
        "Downloading the dataset from http://www.cs.ucf.edu/~aroshan/index_files/Dataset_PitOrlManh/zipped%20images/part2.zip, this might take several minutes since the dataset is about 5 GB."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "http://www.cs.ucf.edu/~aroshan/index_files/Dataset_PitOrlManh/zipped images/part2.zip\n",
            "part2.zip\n"
          ]
        }
      ],
      "source": [
        "import wget\n",
        "url = \"http://www.cs.ucf.edu/~aroshan/index_files/Dataset_PitOrlManh/zipped images/part2.zip\"\n",
        "filename = wget.download(url)\n",
        "print(filename)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {},
      "outputs": [],
      "source": [
        "import zipfile\n",
        "origin_file_path = \"origin\"\n",
        "\n",
        "with zipfile.ZipFile(filename,\"r\") as zip_ref:\n",
        "    zip_ref.extractall(origin_file_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 6600/6600 [01:50<00:00, 59.71it/s]\n"
          ]
        }
      ],
      "source": [
        "# import cv2\n",
        "import PIL\n",
        "from tqdm import tqdm\n",
        "masked_file_path = \"masked\"\n",
        "if not os.path.exists(masked_file_path):\n",
        "    os.mkdir(masked_file_path)\n",
        "\n",
        "for image_file in tqdm(os.listdir(origin_file_path)):\n",
        "    input_path = os.path.join(origin_file_path, image_file)\n",
        "    if not os.path.isfile(input_path):\n",
        "        print(f\"{input_path} is not a file, skipping...\")\n",
        "        continue\n",
        "    img = PIL.Image.open(input_path)\n",
        "    img_ary = np.array(img, dtype=np.uint8)\n",
        "    center = (640, 512)\n",
        "    width, height = 400, 300\n",
        "    startx, starty = center[0] - width//2, center[1] - height//2\n",
        "    img_ary[starty:starty+height, startx:startx+width, :] = 0\n",
        "    PIL.Image.fromarray(img_ary).save(os.path.join(masked_file_path, image_file))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b3LCA0chvctL"
      },
      "source": [
        "## Some steps we can use for data preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LHK1CQBEvQTQ"
      },
      "outputs": [],
      "source": [
        "data_dir = \"C:\\\\Users\\\\Настя\\\\GAN_images\"\n",
        "device = 'cuda'\n",
        "batch_size = 128"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qTUKbb7AvSRm"
      },
      "outputs": [],
      "source": [
        "number_cats = len(os.listdir(data_dir + '\\cats'))\n",
        "print(\"Number of training data samples:\", number_cats)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wFski2KZvT8C"
      },
      "outputs": [],
      "source": [
        "# Chaining image transformations together using torchvision.transforms.Compose method\n",
        "transform = T.Compose([\n",
        "    T.Resize(img_size),\n",
        "    T.CenterCrop(img_size),\n",
        "    T.ToTensor(),\n",
        "    T.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KIyx-0AuvXkH"
      },
      "source": [
        "Using next(iter(_)) we obtain a tensor with dimension (batch_size, num_channels, size, size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YyNo-3m6vVeL"
      },
      "outputs": [],
      "source": [
        "dataset = datasets.ImageFolder(data_dir, transform=transform)\n",
        "dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "\n",
        "images, labels = next(iter(dataloader))\n",
        "images.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5G8iuqVWvZ6Y"
      },
      "outputs": [],
      "source": [
        "fig, axis = plt.subplots(3, 5, figsize=(15,10))\n",
        "for i, ax in enumerate(axis.flat):\n",
        "    with torch.no_grad():\n",
        "        npimg = images[i].numpy()\n",
        "        npimg = np.transpose(npimg, (1,2,0))\n",
        "        ax.imshow(npimg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FSLVBWTRv0Du"
      },
      "source": [
        "## Here we will do data preprocessing with our data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FKYgYCzFv60W"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
